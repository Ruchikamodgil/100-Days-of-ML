# 100-Days-of-ML
#100daysofmlchallenge
<h2> Day1 Learnings:
<h4>-> What is Regression?<br>
-> Linear Regression<br>
-> Mathematics behind Linear Regression<br>
-> Implementation from Scratch<br>
-> Gradient Descent<br>
<h2> Day2 Learnings:
 <h4>-> Polynomial Regression<br>
 -> Why Polynomial Regression?<br>
 -> Underfitting and Overfitting <br>
 -> Implementation of Polynomial Regression
<h2>Day3 Learnings:
 <h4>-> Multiple Linear Regression<br>
 -> Implementation<br>
 -> Feature Selection in Multiple Linear Regression<br>
 -> Need of Data Preprocessing<br>
<h2>Day4 Learnings:
 <h4>->Handling Missing Values<br>
       |<br>
        --->Drop Missing Values<br>
       |<br>
        --->Filling Missing Values<br>
       |<br>
        --->Prediction of Missing Values<br>
 <h4>->Handling Categorical Values<br>
        |<br>
         --->One-Hot Encoding<br>
        |<br>
         --->Label Encoding<br>
 <h2>Day5 Learning:
  <h4>->Dealing with outliers<br>
       |<br>
        --->Detection Methods(Box Plot,Scatter Plot,IQR Score)
  <h4>->Analysis for feature Importance
  <h4>->Feature Scaling<br>
       |<br>
        --->Z-score Normalisation,Min-Max Normalisation,Log Transformation<br>
 <h2>Day6 Learnings:
  <h4>Started Statistics <br>
  ->Average,Variance,Std. Deviation,Prob. Dist. Fns<br>
  ->Binomial Distribution<br>
  ->Poisson Process<br>
 <h2>Day7 Learnings:
  <h4>->Poisson Process<br>
    ->Law of Large numbers<br>
    ->Normal Distribution<br>
 <h2>Day8 Learnings:
  <h4>->Central Limit Theorem<br>
    ->Bernoulli Distribution<br>
    ->Hypothesis Testing<br>
 <h2>Day9 Learnings:
  <h4>->Hypothesis Testing(P-value,One and Two tailed Test,Z and T-statistic,Type I and Type II errors) 
   <h2>Day10 Learnings:
  <h4>->Covariance and correlation<br>
    ->chi-square distribution <br>
    ->ANOVA/F-statistics<br>
   <h2>Day11 Learnings:
    <h4>->Data Visualization on Iris Dataset
   <h2>Day12 Learnings:
    <h4>->Logistic Regression<br>
     ->Implementation of Logistic Regression<br>
     ->Cross Entropy Loss<br>
     ->Optimization using Gradient Descent<br>
     ->Evaluation of Logistic Regression Result
     <h2>Day13 Learnings:
      <h4>->Ridge and Lasso Regression
      <h2>Day14 Learnings:
       <h4>->Ridge and Lasso Regression Implementation
     <h2>Day15 Learnings:
      <h4>->Decision Trees
     <h2>Day16 Learnings:
      <h4>->Decision Tree Implementation
     <h2>Day17 Learnings:
      <h4>->Ensemble Methods<br>
       ->Bagging<br>
       |<br>-->Random Forest
      <h2>Day18 Learnings:
       <h4>->Ensemble Methods<br>
        ->Boosting<br>
        |<br>
        -->Ada-Boost,Gradient Boosting,XGBoost
       <h2>Day19 Learnings:
        <h4>->Random Forest Implementation
       <h2>Day20 Learnings:
        <h4>->Ensemble Methods Implementation
         <h4> Participated in kaggle competition for 1st time 
          
[Kaggle Link](https://www.kaggle.com/ruchikamodgil)
       <h2>Day21 Learnings:
        <h4>->Support Vector Machine
        <h2>Day22 Learnings:
      
          
 [SVM Implementation](https://github.com/Ruchikamodgil/Support-Vector-Machine-Implementation)
        <h2>Day23 Learnings:
         <h4>->K-Nearest Neighbour
        <h2>Day24 Learnings:
         <h4>->KNN Implementation
        <h2>Day25 Learnings:
         <h4>->Bayesian Learning
          <h4>-->Bayes Optimal Classifier,Gibb's Classifier,Naive Bayes Classifier,Gaussian Naive Bayes
         <h2>Day26 Learnings:
          <h4>->Clustering<br>
           |<br>
           -->K-Means Algorithm
          <h2>Day27 Learnings:
           <h4>->Hierarchical Cluestering(Agglomerative)
           <h2>Day28 Learnings:
            <h4>->DBSCAN(Density Based Spatial Clustering of Applications with Noise)
             <h2>Day29 and Day30 Learnings:</h2>
            <h4>->Implementation of Clustering Algorithms in Python<br></h4>

[Clustering Algorithms](https://www.github.com/Ruchikamodgil/Clustering-Algorithms)
           <h2>Day31 and Day32 Learnings:
            <h4>Dimensionality Reduction Techniques<br>
             ->Feature Selection<br>
             ->Feature Extraction
            <h2>Day33 Learnings:
             <h4>->Implementation of PCA on iris dataset using Python<br></h4>           
       
 [Principal Component Analysis](https://www.github.com/Ruchikamodgil/Principal-Component-Analysis)
 <h2>Day34 and Day35 Learnings:
 <h4>-> Numpy and Pandas Revision
  
 [Link](https://github.com/Ruchikamodgil/Basic-Python-Libraries)
             
